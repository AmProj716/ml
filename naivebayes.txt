# Pr 5 Naive Bayes

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/resourcesforpr/spam.csv', header=None, encoding='latin-1')



X = df.iloc[:, 1]
y = df.iloc[:, 0]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


vectorizer = CountVectorizer(binary=True)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)


bnb = BernoulliNB()


bnb.fit(X_train_vec, y_train)


y_pred = bnb.predict(X_train_vec)


accuracy = accuracy_score(y_train, y_pred)
print("Accuracy on training set:", accuracy)

y_pred_test = bnb.predict(X_test_vec)


accuracy_test = accuracy_score(y_test, y_pred_test)
print("Accuracy on test set:", accuracy_test)

import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
import gensim.downloader as api




X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


vectorizer = TfidfVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)


mnb = MultinomialNB()

mnb.fit(X_train_vec, y_train)


y_pred = mnb.predict(X_train_vec)

accuracy = accuracy_score(y_train, y_pred)
print("Accuracy on training set (Multinomial NB):", accuracy)

y_pred_test = mnb.predict(X_test_vec)


accuracy_test = accuracy_score(y_test, y_pred_test)
print("Accuracy on test set (Multinomial NB):", accuracy_test)




word2vec_model = api.load("word2vec-google-news-300")

def document_vector(doc, model):
  """Create a document vector by averaging word vectors."""
  words = doc.split()
  vectors = [model[word] for word in words if word in model]
  if vectors:
    return np.mean(vectors, axis=0)
  else:
    return np.zeros(model.vector_size)


X_train_w2v = [document_vector(doc, word2vec_model) for doc in X_train]
X_test_w2v = [document_vector(doc, word2vec_model) for doc in X_test]



from sklearn.linear_model import LogisticRegression
classifier_w2v = LogisticRegression()
classifier_w2v.fit(X_train_w2v, y_train)


y_pred_w2v = classifier_w2v.predict(X_test_w2v)
accuracy_w2v = accuracy_score(y_test, y_pred_w2v)
print("Accuracy on test set (Word2Vec + Logistic Regression):", accuracy_w2v)


from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt2222
import seaborn as sns


iris = load_iris()
X = iris.data
y = iris.target


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


gnb = GaussianNB()


gnb.fit(X_train, y_train)


y_pred = gnb.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)


cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:\n", cm)


plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix for Iris Dataset")
plt.show()


for i in range(X.shape[1]):
    plt.figure()
    for target in range(len(iris.target_names)):
        plt.hist(X[y == target, i], alpha=0.5, label=iris.target_names[target])
    plt.xlabel(iris.feature_names[i])
    plt.ylabel("Frequency")
    plt.title(f"Distribution of {iris.feature_names[i]} for Each Class")
    plt.legend()
    plt.show()
